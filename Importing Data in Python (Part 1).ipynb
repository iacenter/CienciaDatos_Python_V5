{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data in Python (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\"> \n",
    "\n",
    "- Quick recap   \n",
    "    - List, Dictionaries, Libraries, Subsetting, loc, iloc, Dataframe   \n",
    "    - Sorting rows, Subsetting rows by categorical variables, Adding new columns   \n",
    "    - Aggregating Data   \n",
    "        - Mean and median, Cumulative statistics,Dropping duplicates\n",
    "        - Counting categorical variables, Calculations with .groupby()\n",
    "    - Visualizing Dataframes\n",
    "- Using pandas to import flat files as DataFrames \n",
    "  - Grammatical verbs\n",
    "- Q&A\n",
    "    \n",
    "    \n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:58:31.359603Z",
     "start_time": "2023-08-23T22:58:31.357524Z"
    }
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:15.666478Z",
     "start_time": "2023-08-23T22:57:15.655115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>cont</th>\n",
       "      <th>life_exp</th>\n",
       "      <th>gdp_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2007</td>\n",
       "      <td>31889923.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>43.828</td>\n",
       "      <td>974.580338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Albania</td>\n",
       "      <td>2007</td>\n",
       "      <td>3600523.0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>76.423</td>\n",
       "      <td>5937.029526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2007</td>\n",
       "      <td>33333216.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>72.301</td>\n",
       "      <td>6223.367465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2007</td>\n",
       "      <td>12420476.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.731</td>\n",
       "      <td>4797.231267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>2007</td>\n",
       "      <td>40301927.0</td>\n",
       "      <td>Americas</td>\n",
       "      <td>75.320</td>\n",
       "      <td>12779.379640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>2007</td>\n",
       "      <td>85262356.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>74.249</td>\n",
       "      <td>2441.576404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>2007</td>\n",
       "      <td>4018332.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>73.422</td>\n",
       "      <td>3025.349798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>Yemen, Rep.</td>\n",
       "      <td>2007</td>\n",
       "      <td>22211743.0</td>\n",
       "      <td>Asia</td>\n",
       "      <td>62.698</td>\n",
       "      <td>2280.769906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>2007</td>\n",
       "      <td>11746035.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>42.384</td>\n",
       "      <td>1271.211593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2007</td>\n",
       "      <td>12311143.0</td>\n",
       "      <td>Africa</td>\n",
       "      <td>43.487</td>\n",
       "      <td>469.709298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country  year  population      cont  life_exp       gdp_cap\n",
       "11           Afghanistan  2007  31889923.0      Asia    43.828    974.580338\n",
       "23               Albania  2007   3600523.0    Europe    76.423   5937.029526\n",
       "35               Algeria  2007  33333216.0    Africa    72.301   6223.367465\n",
       "47                Angola  2007  12420476.0    Africa    42.731   4797.231267\n",
       "59             Argentina  2007  40301927.0  Americas    75.320  12779.379640\n",
       "...                  ...   ...         ...       ...       ...           ...\n",
       "1655             Vietnam  2007  85262356.0      Asia    74.249   2441.576404\n",
       "1667  West Bank and Gaza  2007   4018332.0      Asia    73.422   3025.349798\n",
       "1679         Yemen, Rep.  2007  22211743.0      Asia    62.698   2280.769906\n",
       "1691              Zambia  2007  11746035.0    Africa    42.384   1271.211593\n",
       "1703            Zimbabwe  2007  12311143.0    Africa    43.487    469.709298\n",
       "\n",
       "[142 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.gapminder.org/about/\n",
    "\n",
    "gapminder = pd.read_csv(\"data/gapminder.csv\", index_col=0)\n",
    "\n",
    "gapminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:16.179133Z",
     "start_time": "2023-08-23T22:57:16.173056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 142 entries, 11 to 1703\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   country     142 non-null    object \n",
      " 1   year        142 non-null    int64  \n",
      " 2   population  142 non-null    float64\n",
      " 3   cont        142 non-null    object \n",
      " 4   life_exp    142 non-null    float64\n",
      " 5   gdp_cap     142 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(2)\n",
      "memory usage: 7.8+ KB\n"
     ]
    }
   ],
   "source": [
    "gapminder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:18.145351Z",
     "start_time": "2023-08-23T22:57:18.142727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beef\t186\t495\n",
      "Beef\t181\t477\n",
      "Beef\t176\t425\n",
      "Beef\t149\t322\n",
      "Beef\t184\t482\n",
      "Beef\t190\t587\n",
      "Beef\t158\t370\n",
      "Beef\t139\t322\n",
      "Beef\t175\t479\n",
      "Beef\t148\t375\n",
      "Beef\t152\t330\n",
      "Beef\t111\t300\n",
      "Beef\t141\t386\n",
      "Beef\t153\t401\n",
      "Beef\t190\t645\n",
      "Beef\t157\t440\n",
      "Beef\t131\t317\n",
      "Beef\t149\t319\n",
      "Beef\t135\t298\n",
      "Beef\t132\t253\n",
      "Meat\t173\t458\n",
      "Meat\t191\t506\n",
      "Meat\t182\t473\n",
      "Meat\t190\t545\n",
      "Meat\t172\t496\n",
      "Meat\t147\t360\n",
      "Meat\t146\t387\n",
      "Meat\t139\t386\n",
      "Meat\t175\t507\n",
      "Meat\t136\t393\n",
      "Meat\t179\t405\n",
      "Meat\t153\t372\n",
      "Meat\t107\t144\n",
      "Meat\t195\t511\n",
      "Meat\t135\t405\n",
      "Meat\t140\t428\n",
      "Meat\t138\t339\n",
      "Poultry\t129\t430\n",
      "Poultry\t132\t375\n",
      "Poultry\t102\t396\n",
      "Poultry\t106\t383\n",
      "Poultry\t94\t387\n",
      "Poultry\t102\t542\n",
      "Poultry\t87\t359\n",
      "Poultry\t99\t357\n",
      "Poultry\t107\t528\n",
      "Poultry\t113\t513\n",
      "Poultry\t135\t426\n",
      "Poultry\t142\t513\n",
      "Poultry\t86\t358\n",
      "Poultry\t143\t581\n",
      "Poultry\t152\t588\n",
      "Poultry\t146\t522\n",
      "Poultry\t144\t545\n"
     ]
    }
   ],
   "source": [
    "# Open a file: file\n",
    "file = open('data/hotdogs.txt', mode='r')\n",
    "\n",
    "# https://docs.python.org/3/library/functions.html\n",
    "\n",
    "# https://docs.python.org/3/library/functions.html#open\n",
    "\n",
    "# Print it\n",
    "print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:22.175258Z",
     "start_time": "2023-08-23T22:57:22.172848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing entire text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:23.264865Z",
     "start_time": "2023-08-23T22:57:23.262199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1. Loomings.\n",
      "\n",
      "Call me Ishmael. Some years ago--never mind how long precisely--having\n",
      "little or no money in my purse, and nothing particular to interest me on\n",
      "shore, I thought I would sail about a little and see the watery part of\n",
      "the world. It is a way I have of driving off the spleen and regulating\n",
      "the circulation. Whenever I find myself growing grim about the mouth;\n",
      "whenever it is a damp, drizzly November in my soul; whenever I find\n",
      "myself involuntarily pausing before coffin warehouses, and bringing up\n",
      "the rear of every funeral I meet; and especially whenever my hypos get\n",
      "such an upper hand of me, that it requires a strong moral principle to\n",
      "prevent me from deliberately stepping into the street, and methodically\n",
      "knocking people's hats off--then, I account it high time to get to sea\n",
      "as soon as I can. This is my substitute for pistol and ball. With a\n",
      "philosophical flourish Cato throws himself upon his sword; I quietly\n",
      "take to the ship. There is nothing surprising in this. If they but knew\n",
      "it, almost all men in their degree, some time or other, cherish very\n",
      "nearly the same feelings towards the ocean with me.\n"
     ]
    }
   ],
   "source": [
    "# Open a file: file\n",
    "file = open('data/moby_dick.txt', mode='r')\n",
    "\n",
    "# Print it\n",
    "print(file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:25.473111Z",
     "start_time": "2023-08-23T22:57:25.470865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:26.024968Z",
     "start_time": "2023-08-23T22:57:26.022234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 1. Loomings.\n",
      "\n",
      "\n",
      "\n",
      "Call me Ishmael. Some years ago--never mind how long precisely--having\n",
      "\n",
      "little or no money in my purse, and nothing particular to interest me on\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read & print the first 3 lines\n",
    "with open('data/moby_dick.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing different datatypes\n",
    "The file seaslug.txt\n",
    "\n",
    "- has a text header, consisting of strings   \n",
    "- is tab-delimited.   \n",
    "\n",
    "These data consists of percentage of sea slug larvae that had metamorphosed in a given time period. <http://www.stat.ucla.edu/~rgould/datasets/aboutseaslugs.html>\n",
    "\n",
    "Due to the header, if you tried to import it as-is using np.loadtxt(), Python would throw you a ValueError and tell you that it could not convert string to float. There are two ways to deal with this: firstly, you can set the data type argument dtype equal to str (for string).\n",
    "\n",
    "Alternatively, you can skip the first row as we have seen before, using the skiprows argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:27.531215Z",
     "start_time": "2023-08-23T22:57:27.526362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Time' 'Percent']\n",
      " ['99' '0.067']\n",
      " ['99' '0.133']]\n"
     ]
    }
   ],
   "source": [
    "# Assign filename: file\n",
    "file = 'data/seaslug.txt'\n",
    "\n",
    "#https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html \n",
    "\n",
    "# Import file: data\n",
    "data = np.loadtxt(file, delimiter='\\t', dtype=str)\n",
    "\n",
    "# Print the first element of data\n",
    "print(data[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:30.010967Z",
     "start_time": "2023-08-23T22:57:30.006649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.90e+01 6.70e-02]\n",
      " [9.90e+01 1.33e-01]\n",
      " [9.90e+01 6.70e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Import data as floats and skip the first row: data_float\n",
    "data_float = np.loadtxt(file, delimiter='\\t', \n",
    "                        dtype=float, \n",
    "                        skiprows=1)\n",
    "\n",
    "# https://numpy.org/doc/1.20/reference/generated/numpy.loadtxt.html\n",
    "\n",
    "# Print the 10th element of data_float\n",
    "print(data_float[0:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pandas to import flat files as DataFrames (1)\n",
    " \n",
    " The DataFrame object in pandas is a more appropriate structure in which to store such data and, thankfully, we can easily import files of mixed data types as DataFrames using the pandas functions **read_csv()** and **read_table()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:32.272776Z",
     "start_time": "2023-08-23T22:57:32.262106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        S  \n",
       "1          PC 17599  71.2833   C85        C  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3            113803  53.1000  C123        S  \n",
       "4            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'data/titanic.csv'\n",
    "\n",
    "# Read the file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# View the head of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing your pandas import\n",
    "The pandas package is also great at dealing with many of the issues you will encounter when importing data as a data scientist, such as comments occurring in flat files, empty lines and missing values. Note that missing values are also commonly referred to as NA or NaN. \n",
    "\n",
    "We are now going to import a slightly corrupted copy of the Titanic dataset titanic_corrupt.txt, which\n",
    "\n",
    "- contains comments after the character '#'   \n",
    "\n",
    "- is tab-delimited.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:37.969736Z",
     "start_time": "2023-08-23T22:57:37.957949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S #dfafdad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599#to</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex   Age  SibSp  Parch  \\\n",
       "0            1         0       3    male  22.0      1      0   \n",
       "1            2         1       1  female  38.0      1      0   \n",
       "2            3         1       3  female  26.0      0      0   \n",
       "3            4         1       1  female  35.0      1      0   \n",
       "4            5         0       3    male  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin    Embarked  \n",
       "0         A/5 21171   7.2500   NaN  S #dfafdad  \n",
       "1       PC 17599#to  71.2833   C85           C  \n",
       "2  STON/O2. 3101282   7.9250   NaN           S  \n",
       "3            113803  53.1000  C123           S  \n",
       "4            373450   8.0500   NaN           S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'data/titanic_corrupt.txt'\n",
    "\n",
    "# Import file: data\n",
    "data = pd.read_csv(file, \n",
    "                   sep='\\t', \n",
    "                   comment='#', \n",
    "                   na_values=['Nothing'])\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing sheets in Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T22:57:49.049860Z",
     "start_time": "2023-08-23T22:57:48.661951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1960-1966', '1967-1974', '1975-2011']\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign spreadsheet filename: file\n",
    "file = 'data/urbanpop.xlsx'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.parse.html\n",
    "\n",
    "# Print sheet names\n",
    "print(xl.sheet_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing sheets from Excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xl.parse('1960-1966')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/version/0.16.2/generated/pandas.ExcelFile.parse.html\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sheet into a DataFrame by index: df2\n",
    "df2 = xl.parse(1)\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing your spreadsheet import\n",
    "\n",
    "Here, you'll parse your spreadsheets and use additional arguments to skip rows, rename columns and select only particular columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign spreadsheet filename: file\n",
    "file = 'data/battledeath.xlsx'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Print sheet names\n",
    "print(xl.sheet_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the first sheet and rename the columns: df1\n",
    "df1 = xl.parse(0, skiprows=[0], names=['Country', 'Age (2002)'])\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the first column of the second sheet and rename the column: df2\n",
    "df2 = xl.parse(1, parse_cols=[0], skiprows=[0], names=['Country', 'Age (2004)'])\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read_excel\n",
    "\n",
    "- Supports xls, xlsx, xlsm, xlsb, odf, ods and odt file extensions read from a local filesystem or URL. \n",
    "\n",
    "- Supports an option to read a single sheet or a list of sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('data/urbanpop.xlsx')\n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\n",
    "    open('data/urbanpop.xlsx', 'rb'),\n",
    "              sheet_name='1967-1974')  \n",
    "\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html\n",
    "\n",
    "df1 .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping range of rows \n",
    "\n",
    "df1 = pd.read_excel(\"data/urbanpop.xlsx\",\n",
    "                   sheet_name = \"1975-2011\",\n",
    "                   skiprows = range(1, 5))\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript Object Notation (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_json = pd.read_json(\"data/stocks.json\")\n",
    "\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "\n",
    "df_from_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_json.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gapminder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data from the Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V5/main/data/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and reading flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V5/main/data/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing non-flat files from the web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V5/main/data/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Print the sheetnames \n",
    "print(xl.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, NOT its index)\n",
    "print(xl['1700'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V5/main/data/urbanpop.xlsx'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "xl = pd.read_excel(url, sheet_name=\"1960-1966\")\n",
    "\n",
    "# Print the head of the first sheet \n",
    "xl.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://raw.githubusercontent.com/iacenter/CienciaDatos_Python_V5/main/data/stocks.json'\n",
    "\n",
    "# Read in all sheets of Excel file: xl\n",
    "df_from_json = pd.read_json(url)\n",
    "\n",
    "df_from_json.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing SAS files\n",
    "\n",
    "- <https://www.sas.com/en_us/home.html>\n",
    "\n",
    "- <https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.5/hostwin/n0sk6o15955yoen19n9ghdziqw1u.htm#p0sgui0b1o9nljn1crwkx9k7yr4w>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sas7bdat\n",
    "\n",
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('data/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "df_sas.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Stata files\n",
    "\n",
    "<https://www.stata.com/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df = pd.read_stata('data/disarea.dta')\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MatLab (.mat) files\n",
    "\n",
    "<https://www.mathworks.com/products/matlab.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat = scipy.io.loadmat('data/albeck_gene_expression.mat')\n",
    "#mat = scipy.io.loadmat('data/ja_data2.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the keys of the MATLAB dictionary\n",
    "mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print(type(mat['CYratioCyt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "print(np.shape(mat['CYratioCyt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using h5py to import HDF5 files\n",
    "\n",
    "<https://www.hdfgroup.org/solutions/hdf5/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = 'data/L-L1_LOSC_4_V1-1126259446-32.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, 'r')\n",
    "\n",
    "# Print the datatype of the loaded file\n",
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the keys of the file\n",
    "for key in data.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case:\n",
    "\n",
    "- txt file has no column headers\n",
    "\n",
    "- Missing values\n",
    "\n",
    "- Output \n",
    "\n",
    "    - Jupyter notebook\n",
    "\n",
    "    - Description of the analysis\n",
    "    \n",
    "    - **Deadline Sunday 27th**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-23T23:06:08.222609Z",
     "start_time": "2023-08-23T23:06:08.187466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_month_day</th>\n",
       "      <th>dec_date</th>\n",
       "      <th>sunspots</th>\n",
       "      <th>definite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1818-01-01</td>\n",
       "      <td>1818.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1818-01-02</td>\n",
       "      <td>1818.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1818-01-03</td>\n",
       "      <td>1818.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1818-01-04</td>\n",
       "      <td>1818.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1818-01-05</td>\n",
       "      <td>1818.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71856</th>\n",
       "      <td>2014-09-26</td>\n",
       "      <td>2014.735</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71857</th>\n",
       "      <td>2014-09-27</td>\n",
       "      <td>2014.738</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71858</th>\n",
       "      <td>2014-09-28</td>\n",
       "      <td>2014.741</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71859</th>\n",
       "      <td>2014-09-29</td>\n",
       "      <td>2014.743</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71860</th>\n",
       "      <td>2014-09-30</td>\n",
       "      <td>2014.746</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71861 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year_month_day  dec_date  sunspots  definite\n",
       "0         1818-01-01  1818.004       NaN         1\n",
       "1         1818-01-02  1818.007       NaN         1\n",
       "2         1818-01-03  1818.010       NaN         1\n",
       "3         1818-01-04  1818.012       NaN         1\n",
       "4         1818-01-05  1818.015       NaN         1\n",
       "...              ...       ...       ...       ...\n",
       "71856     2014-09-26  2014.735     111.0         0\n",
       "71857     2014-09-27  2014.738     122.0         0\n",
       "71858     2014-09-28  2014.741     130.0         0\n",
       "71859     2014-09-29  2014.743     121.0         0\n",
       "71860     2014-09-30  2014.746     120.0         0\n",
       "\n",
       "[71861 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge = pd.read_csv('data/ISSN_D_tot_CLEAN_5.csv')\n",
    "\n",
    "challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Google Drive/PhD/Software/Python/Code/CienciaDatos_Python/Importing Data in Python (Part 1).ipynb",
    "public": false
   },
   "id": ""
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.82px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
